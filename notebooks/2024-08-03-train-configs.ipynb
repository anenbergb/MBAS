{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "238c7eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4f4fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config_fpath = \"/home/bryan/data/mbas_nnUNet_preprocessed/Dataset101_MBAS/MedNeXtPlans.json\"\n",
    "\n",
    "new_config_fpath = \"/home/bryan/data/mbas_nnUNet_preprocessed/Dataset101_MBAS/MedNeXtPlans_2024_08_03.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ed7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_config_fpath, \"r\") as f:\n",
    "    base_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12b75627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_params(\n",
    "    base_config,\n",
    "    batch_size = 2,\n",
    "    patch_size = (16, 256, 256),\n",
    "    features_per_stage = (32, 64, 128, 256, 320, 320, 320),\n",
    "    stem_kernel_size = 1,\n",
    "    kernel_sizes = [\n",
    "        (1,3,3),\n",
    "        (1,3,3), \n",
    "        (3,3,3),\n",
    "        (3,3,3),\n",
    "        (3,3,3),\n",
    "        (3,3,3),\n",
    "        (3,3,3),\n",
    "    ],\n",
    "    strides = [\n",
    "        (1,1,1),\n",
    "        (1,2,2),\n",
    "        (1,2,2),\n",
    "        (2,2,2),\n",
    "        (2,2,2),\n",
    "        (2,2,2),\n",
    "        (2,2,2),\n",
    "    ],\n",
    "    n_blocks_per_stage = [3,4,6,6,6,6,6],\n",
    "    exp_ratio_per_stage = [2,3,4,4,4,4,4],\n",
    "    n_blocks_per_stage_decoder = None,\n",
    "    exp_ratio_per_stage_decoder = None,\n",
    "    norm_type = \"group\",\n",
    "    enable_affine_transform = False,\n",
    "    decode_stem_kernel_size=3,\n",
    "    override_down_kernel_size = True,\n",
    "    down_kernel_size = 1,\n",
    "    boundary_loss_alpha_stepsize = 5,\n",
    "    boundary_loss_alpha_warmup_epochs = 250,\n",
    "    boundary_loss_alpha_max = 0.75,\n",
    "    oversample_foreground_percent = 1.0,\n",
    "    probabilistic_oversampling = False,\n",
    "    sample_class_probabilities = None,\n",
    "    alpha_stepwise_warmup_scaled = True,\n",
    "    \n",
    "):\n",
    "    config_copy = copy.deepcopy(base_config)\n",
    "    config_copy[\"batch_size\"] = batch_size\n",
    "    config_copy[\"patch_size\"] = patch_size\n",
    "    config_copy[\"boundary_loss_alpha_stepsize\"] = boundary_loss_alpha_stepsize\n",
    "    config_copy[\"boundary_loss_alpha_warmup_epochs\"] = boundary_loss_alpha_warmup_epochs\n",
    "    config_copy[\"boundary_loss_alpha_max\"] = boundary_loss_alpha_max\n",
    "    config_copy[\"alpha_stepwise_warmup_scaled\"] = alpha_stepwise_warmup_scaled\n",
    "\n",
    "    config_copy[\"oversample_foreground_percent\"] = oversample_foreground_percent\n",
    "    config_copy[\"probabilistic_oversampling\"] = probabilistic_oversampling\n",
    "    config_copy[\"sample_class_probabilities\"] = sample_class_probabilities\n",
    "    \n",
    "\n",
    "    \n",
    "    arch = config_copy[\"architecture\"][\"arch_kwargs\"]\n",
    "    \n",
    "    n_stages = len(features_per_stage)\n",
    "    assert len(kernel_sizes) == n_stages\n",
    "    assert len(strides) == n_stages\n",
    "    assert len(n_blocks_per_stage) == n_stages\n",
    "    assert len(exp_ratio_per_stage) == n_stages\n",
    "    if n_blocks_per_stage_decoder is None:\n",
    "        n_blocks_per_stage_decoder = n_blocks_per_stage[:-1][::-1] + [n_blocks_per_stage[0]]\n",
    "    assert len(n_blocks_per_stage_decoder) == n_stages\n",
    "    if exp_ratio_per_stage_decoder is None:\n",
    "        exp_ratio_per_stage_decoder = exp_ratio_per_stage[:-1][::-1] + [exp_ratio_per_stage[0]]\n",
    "    assert len(exp_ratio_per_stage_decoder) == n_stages\n",
    "    \n",
    "    arch[\"n_stages\"] = n_stages\n",
    "    arch[\"features_per_stage\"] = features_per_stage\n",
    "    arch[\"stem_kernel_size\"] = stem_kernel_size\n",
    "    arch[\"kernel_sizes\"] = kernel_sizes\n",
    "    arch[\"strides\"] = strides\n",
    "    arch[\"n_blocks_per_stage\"] = n_blocks_per_stage\n",
    "    arch[\"exp_ratio_per_stage\"] = exp_ratio_per_stage\n",
    "    arch[\"n_blocks_per_stage_decoder\"] = n_blocks_per_stage_decoder\n",
    "    arch[\"exp_ratio_per_stage_decoder\"] = exp_ratio_per_stage_decoder\n",
    "    arch[\"norm_type\"] = norm_type\n",
    "    arch[\"enable_affine_transform\"] = enable_affine_transform\n",
    "    arch[\"decode_stem_kernel_size\"] = decode_stem_kernel_size\n",
    "    arch[\"override_down_kernel_size\"] = override_down_kernel_size\n",
    "    arch[\"down_kernel_size\"] = down_kernel_size\n",
    "    return config_copy\n",
    "\n",
    "def set_cascade_relationships(config, next_stages = [], prev_stage = \"3d_fullres\"):\n",
    "#     config[\"configurations\"][prev_stage][\"next_stage\"] = next_stages\n",
    "    for next_stage in next_stages:\n",
    "        config[\"configurations\"][next_stage][\"previous_stage\"] = prev_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9da3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_config = base_config[\"configurations\"][\"3d_fullres\"]\n",
    "\n",
    "\n",
    "new_config = copy.deepcopy(base_config)\n",
    "new_config[\"plans_name\"] = os.path.basename(os.path.splitext(new_config_fpath)[0])\n",
    "new_config[\"configurations\"] = {}\n",
    "new_config[\"configurations\"][\"slim_128_oversample_05_alpha05_warm250_max075\"] = set_model_params(\n",
    "    base_model_config,\n",
    "    override_down_kernel_size = False,\n",
    "    features_per_stage = (32, 64, 128, 128, 128, 128, 128),\n",
    "    oversample_foreground_percent=1.0,\n",
    "    probabilistic_oversampling = True,\n",
    "    sample_class_probabilities = {1: 0.5, 2: 0.25, 3: 0.25},\n",
    "    boundary_loss_alpha_stepsize = 5,\n",
    "    boundary_loss_alpha_warmup_epochs = 250,\n",
    "    boundary_loss_alpha_max = 0.75,\n",
    "    alpha_stepwise_warmup_scaled = False\n",
    ")\n",
    "new_config[\"configurations\"][\"slim_128_oversample_05_alpha05_warm250_max050\"] = set_model_params(\n",
    "    base_model_config,\n",
    "    override_down_kernel_size = False,\n",
    "    features_per_stage = (32, 64, 128, 128, 128, 128, 128),\n",
    "    oversample_foreground_percent=1.0,\n",
    "    probabilistic_oversampling = True,\n",
    "    sample_class_probabilities = {1: 0.5, 2: 0.25, 3: 0.25},\n",
    "    boundary_loss_alpha_stepsize = 5,\n",
    "    boundary_loss_alpha_warmup_epochs = 250,\n",
    "    boundary_loss_alpha_max = 0.50,\n",
    "    alpha_stepwise_warmup_scaled = False,\n",
    ")\n",
    "new_config[\"configurations\"][\"slim_128_oversample_05_alpha05_warm250_max075_scaled\"] = set_model_params(\n",
    "    base_model_config,\n",
    "    override_down_kernel_size = False,\n",
    "    features_per_stage = (32, 64, 128, 128, 128, 128, 128),\n",
    "    oversample_foreground_percent=1.0,\n",
    "    probabilistic_oversampling = True,\n",
    "    sample_class_probabilities = {1: 0.5, 2: 0.25, 3: 0.25},\n",
    "    boundary_loss_alpha_stepsize = 5,\n",
    "    boundary_loss_alpha_warmup_epochs = 250,\n",
    "    boundary_loss_alpha_max = 0.75,\n",
    "    alpha_stepwise_warmup_scaled = True,\n",
    ")\n",
    "new_config[\"configurations\"][\"slim_128_oversample_05_alpha05_warm250_max050_scaled\"] = set_model_params(\n",
    "    base_model_config,\n",
    "    override_down_kernel_size = False,\n",
    "    features_per_stage = (32, 64, 128, 128, 128, 128, 128),\n",
    "    oversample_foreground_percent=1.0,\n",
    "    probabilistic_oversampling = True,\n",
    "    sample_class_probabilities = {1: 0.5, 2: 0.25, 3: 0.25},\n",
    "    boundary_loss_alpha_stepsize = 5,\n",
    "    boundary_loss_alpha_warmup_epochs = 250,\n",
    "    boundary_loss_alpha_max = 0.50,\n",
    "    alpha_stepwise_warmup_scaled = True,\n",
    ")\n",
    "new_config[\"configurations\"][\"slim_128_oversample_05_alpha05_warm500_max025_scaled\"] = set_model_params(\n",
    "    base_model_config,\n",
    "    override_down_kernel_size = False,\n",
    "    features_per_stage = (32, 64, 128, 128, 128, 128, 128),\n",
    "    oversample_foreground_percent=1.0,\n",
    "    probabilistic_oversampling = True,\n",
    "    sample_class_probabilities = {1: 0.5, 2: 0.25, 3: 0.25},\n",
    "    boundary_loss_alpha_stepsize = 5,\n",
    "    boundary_loss_alpha_warmup_epochs = 500,\n",
    "    boundary_loss_alpha_max = 0.25,\n",
    "    alpha_stepwise_warmup_scaled = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b7f30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(new_config_fpath, \"w\") as f:\n",
    "    json.dump(new_config, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mbas]",
   "language": "python",
   "name": "conda-env-mbas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
